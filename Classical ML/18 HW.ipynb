{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок теоретических вопросов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Почему считается, что деревья склонны к переобучению?*: \n",
    "\n",
    "1. Это было замечено эмпирически.\n",
    "2. Потому что деревья очень мощны, то есть могут восстановить практически любую зависимость в данных.\n",
    "3. Из-за связи деревьев с линейными моделями, то есть дерево – это, по сути, линейная модель над какими-то признаками.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 2)** Факт, показанный как на практике и лекциях, так и в домашнем задании. Деревья разбивают сколько угодно сложным образом признаковое пространство на простые кусочки.\n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Как снижение минимального количества объектов в листовой вершине повлияет на качество на обучающей и тестовой выборках*: \n",
    "\n",
    "1.\tОшибка на обучающей и тестовых выборках будет падать\n",
    "2.\tОшибка на обучающей выборке будет уменьшаться, а на тестовой падать до какого-то момента, а затем увеливаться\n",
    "3.\tНельзя точно определить\n",
    "4.\tОшибка на тестовой выборке будет падать, насчет ошибки на обучающей выборке нельзя сказать точно\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 2)** Чем больше минимальное количество обхектов в листовой вершине, тем более \"общее\" разделение мы требуем от требования. То есть улавливание более общих, нежели шумящих и частных закономерностей.\n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Представим, что у нас имеются 2 дерева, уже обученных на одних и тех же данных. Отличаются они значениями гиперпараметров. Для первого дерева значения следующие: максимальная глубина = 8, минимальное количество объектов в листовой вершине=7. Для второго: максимальная глубина = 15, минимальное количество объектов в листовой вершине=5. Какое из них, по вашему мнению, выдаст худшее качество на тестовой выборке?*: \n",
    "\n",
    "1.\tВторое, так как максимальная глубина значительно больше, дерево успеет подогнаться под выбросы и тд.\n",
    "2.\tПервое, так как глубина недостаточно большая, данные могут оказаться сложными, дерево не успеет повторить зависимость. \n",
    "3.\tВопрос некорректен, так как мы не знаем, как устроены данные. Нам может хватить глубины 8, а может не хватить и 15. \n",
    "4.\tВторое, так как такая большая глубина и малое количество объектов в листе почти что гарантируют переобучение\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 3)** В машинном обучении, в действительности, не бывает идеального рецепта или элексира. Каждая крупица данных требует индивидуального подхода и тонны экспериментов!\n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок практики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим датасет с машинами. Цель - верно восстанавливать для каждой из них цену продажи!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('autos.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Колонка с тергетом - \"selling price\"\n",
    "\n",
    "X = data.drop(\"selling_price\", axis=1)\n",
    "y = data[\"selling_price\"]\n",
    "\n",
    "### Будем замерять MSLE!\n",
    "### Поэтому прологарифмируем таргет\n",
    "### А после оптимизируем MSE\n",
    "\n",
    "y = y.apply(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Разделим выборку на трейн и тест!\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание__ \n",
    "\n",
    "Реализуйте свой MeanTargetEncoder с добавленем некоторого шума!\n",
    "\n",
    "Однажды в лекционном материале, обсуждая счетчики, мы говорили с вами о том, что из-за них модели могут переобучаться. Один из способов бороться с этим - валидировать расчеты среднего таргета (стратегия отложенной выборки / расчеты на кросс-валидации). Но есть еще проще!\n",
    "\n",
    "Можно просто к значению счетчика добавить случайный шум (зашумить данные)!\n",
    "\n",
    "Напомним, что рассчитываться новые признаки должны по такой формуле:\n",
    "\n",
    "$$\n",
    "g_j(x, X) = \\frac{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)][y_i = +1]}{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)]} + C * \\epsilon\n",
    "$$\n",
    "\n",
    "\n",
    "Пусть шум будет случайной величиной из нормального стандартного распределения, то есть $\\epsilon \\sim N(0, 1) $, а $ C = 0.006$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создавай свой класс-трансформер, наследуйтесь от классов `BaseEstimator, TransformerMixin` из `sklearn.base`. Трансформер не должен модифицировать передаваемую ему выборку inplace, а все необходимые статистики нужно считать только по обучающей выборке в методе `fit`. Ваш трансформер должен принимать при инициализации список из категориальных признаков и список из числовых признаков. На выходе должен получиться датасет того же размера с измененными категориальными признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Разделим колонки на вещественные и категориальные\n",
    "\n",
    "object_cols = ['name', 'year', 'fuel', 'seller_type', 'transmission', 'owner']\n",
    "num_cols = ['km_driven']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Применим ко всем категориальным колонкам object type\n",
    "\n",
    "X[object_cols] = X[object_cols].astype(object)\n",
    "X_test[object_cols] = X_test[object_cols].astype(object)\n",
    "X_train[object_cols] = X_train[object_cols].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "### Функция считает среднее и добавляет шум из стандартного нормального распределения\n",
    "\n",
    "def func1(x):\n",
    "    return np.sum(x) / x.size + 0.006 * np.random.normal(loc = 0.0, scale = 1.0, size =1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import itertools\n",
    "\n",
    "### Реализуем класс, считающий средние значения по таргету\n",
    "### И немного зашумляющий их\n",
    "### Данная реализация не претендует на звание самой лучшей!\n",
    "### Любые другие, работающие за адекватное время, тоже подойдут\n",
    "### Советуем потыкать и разобраться, если самостоятельно во время \n",
    "### Выполнения ДЗ не получилось!\n",
    "\n",
    "class MeanTargetEncoderNoise(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, categorical, numeric):\n",
    "        self.categorical = categorical\n",
    "        self.numeric = numeric\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        X['y'] = y\n",
    "        \n",
    "        arr = []\n",
    "        \n",
    "        for i in self.categorical:\n",
    "            \n",
    "            temp = X.groupby(i).agg({'y':[func1]}).reset_index()\n",
    "            arr.append((list(temp[i]), list(temp['y']['func1'])))\n",
    "            \n",
    "        \n",
    "        self.arr = arr\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def transform(self, df):\n",
    "        \n",
    "        arr = self.arr\n",
    "        \n",
    "        temp = pd.DataFrame()\n",
    "        \n",
    "        c = 0\n",
    "        \n",
    "        for i in self.categorical:\n",
    "            \n",
    "            setik = set(df[i].unique())\n",
    "            setik.difference_update(set(arr[c][0]))\n",
    "\n",
    "            column = df[i].replace(arr[c][0], arr[c][1]).reset_index()[i]\n",
    "            column = column.replace(list(setik), 0).reset_index()[i]\n",
    "\n",
    "            temp = pd.concat([temp, column], axis=1)\n",
    "            \n",
    "            c+=1        \n",
    "\n",
    "        temp = pd.concat([df[self.numeric].reset_index(drop=True), temp], axis=1)\n",
    "        \n",
    "        return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Проверим работоспособность\n",
    "\n",
    "np.random.seed(1)\n",
    "transformer = MeanTargetEncoderNoise(categorical=object_cols, numeric=num_cols)\n",
    "\n",
    "transformer.fit(X_train, y_train)\n",
    "\n",
    "train = transformer.transform(X_train)\n",
    "test = transformer.transform(X_test)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите несколько деревьев, перебирая максимальную глубину алгоритма из списка `max_depth_list`, а остальные параметры оставьте дефолтными. Выведите лучшее значение гиперпараметра. Постройте график зависимости MSLE на тестовой выборке от значения гиперпараметра. Воспользуйтесь `Pipeline` без `GridSearch`. Проделайте то же самое с `min_samples_split`, `min_impurity_decrease`, `max_leaf_nodes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Зададим сетку параметров\n",
    "\n",
    "max_depth_list = [3, 5, 8, 12]\n",
    "min_samples_split_list = [10, 50, 100, 500]\n",
    "min_impurity_decrease_list = [0, 0.1, 0.15, 0.2]\n",
    "max_leaf_nodes_list = [100, 200, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Найдем лучшую глубину (при прочих дефолтных параметрах)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "np.random.seed(1)\n",
    "rmse1 = []\n",
    "\n",
    "\n",
    "for max_depth in max_depth_list:\n",
    "\n",
    "    pipe = Pipeline([(\"custom_transformer\",\n",
    "                  MeanTargetEncoderNoise(categorical=object_cols, numeric=num_cols)),\n",
    "                  \n",
    "                  \n",
    "                 (\"decision_tree\", \n",
    "                  DecisionTreeRegressor(max_depth=max_depth))])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    rmse1.append(mse(preds, y_test, squared=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Найдем лучшее минимальное количество объектов в вершине (при прочих дефолтных параметрах)\n",
    "\n",
    "rmse2 = []\n",
    "np.random.seed(1)\n",
    "\n",
    "for min_samples_split in min_samples_split_list:\n",
    "\n",
    "    pipe = Pipeline([(\"custom_transformer\",\n",
    "                  MeanTargetEncoderNoise(categorical=object_cols, numeric=num_cols)),\n",
    "                  \n",
    "                  \n",
    "                 (\"decision_tree\", \n",
    "                  DecisionTreeRegressor(min_samples_split=min_samples_split))])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    rmse2.append(mse(preds, y_test, squared=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Найдем лучшее максимальное количество листьев (при прочих дефолтных параметрах)\n",
    "\n",
    "rmse3 = []\n",
    "np.random.seed(1)\n",
    "\n",
    "for max_leaf_nodes in max_leaf_nodes_list:\n",
    "\n",
    "    pipe = Pipeline([(\"custom_transformer\",\n",
    "                  MeanTargetEncoderNoise(categorical=object_cols, numeric=num_cols)),\n",
    "                  \n",
    "                  \n",
    "                 (\"decision_tree\", \n",
    "                  DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes))])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    rmse3.append(mse(preds, y_test, squared=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Найдем лучшее минимальное улучшения критерия качества \n",
    "### при выборе предиката (при прочих дефолтных параметрах)\n",
    "\n",
    "rmse4 = []\n",
    "np.random.seed(1)\n",
    "\n",
    "for min_impurity_decrease in min_impurity_decrease_list:\n",
    "\n",
    "    pipe = Pipeline([(\"custom_transformer\",\n",
    "                  MeanTargetEncoderNoise(categorical=object_cols, numeric=num_cols)),\n",
    "                  \n",
    "                  \n",
    "                 (\"decision_tree\", \n",
    "                  DecisionTreeRegressor(min_impurity_decrease=min_impurity_decrease))])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    rmse4.append(mse(preds, y_test, squared=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изобразим результаты качества в зависимости от изменения отдельных параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(max_depth_list, rmse1)\n",
    "plt.title('msle от max_depth')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('rmse');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(min_samples_split_list, rmse2)\n",
    "plt.title('msle от min_samples_split')\n",
    "plt.xlabel('min_samples_split')\n",
    "plt.ylabel('rmse');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(max_leaf_nodes_list, rmse3)\n",
    "plt.title('msle от max_leaf_nodes')\n",
    "plt.xlabel('max_leaf_nodes')\n",
    "plt.ylabel('rmse');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(min_impurity_decrease_list, rmse4)\n",
    "plt.title('msle от min_impurity_decrease')\n",
    "plt.xlabel('min_impurity_decrease')\n",
    "plt.ylabel('rmse');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберите лучшую комбинацию параметров, используя `GridSearchCV` и набор массивов значений параметров из предыдущего задания. Для лучшей комбинации посчитайте MSLE на тестовой выборке. Получились ли лучшие параметры такими же, как если бы вы подбирали их по-отдельности при остальных гиперпараметрах по умолчанию (предыдущее задание)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "param_grid = {\n",
    "    \"decision_tree__max_depth\": [3, 5, 8, 12],\n",
    "    \"decision_tree__min_samples_split\": [10, 50, 100, 500],\n",
    "    \"decision_tree__min_impurity_decrease\": [0, 0.1, 0.15, 0.2],\n",
    "    \"decision_tree__max_leaf_nodes\": [100, 200, 500]\n",
    "}\n",
    "np.random.seed(1)\n",
    "\n",
    "pipe = Pipeline([(\"custom_transformer\",\n",
    "                  MeanTargetEncoderNoise(categorical=object_cols, numeric=num_cols)),\n",
    "                  \n",
    "                  \n",
    "                 (\"decision_tree\", \n",
    "                  DecisionTreeRegressor())])\n",
    "\n",
    "search = GridSearchCV(pipe, \n",
    "                      param_grid, \n",
    "                      cv=4,\n",
    "                      scoring='neg_mean_squared_error',\n",
    "                      verbose=10)\n",
    "\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Замерим MSE на лучшей модели\n",
    "\n",
    "mse(search.best_estimator_.predict(X_test), y_test, squared=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8db21564b35bbdf2f1295d2e540489014671416f5dc577a5b9d4ca56833a3713"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

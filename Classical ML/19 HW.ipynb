{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок теоретических вопросов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*В чем достоинство алгоритма случайного леса?*: \n",
    "\n",
    "1. Совмещая несколько деревьев, мы можем аппроксимировать любую зависимость в наших данных\n",
    "2. Благодаря бэггингу, ошибки деревьев, можно сказать, почти независимы. Поэтому можно показать, что использование леса серьезно снизит ошибку в сравнении с деревом\n",
    "3. Можно использовать деревья любой глубины, даже неглубокие. Если взять их много, то качество все равно будет высоким. Поэтому можно не тратить много времени, на обучение модели.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 2)** В действительности, бутстрапируя выборку и обучая на полученных сэмплах базовые модели, можно убедиться в том, что ошибка композиции (при условиях независимости между моделями) будет уменьшаться кратно размеру ансамбля.\n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Как правильно бороться с переобучением стекинга?*: \n",
    "\n",
    "1.\tПравильно делить выборку. Например, обучать базовые модели можно на одной части тренировочной выборки, а метамодель на другой ее части. Качество отслеживать по отложенной выборке.\n",
    "2.\tДостаточно брать модели, не склонные к переобучению. Например, неглубокие деревья\n",
    "3.\tНеобходимо обучать метамодель на тех же данных, что и базовые модели, чтобы не учитывать ошибки базовых моделей на новых данных.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 1)** Если базовая модель переобучится на тренировочной выборке, то метамодель просто-напросто будет занулять веса у всех остальных моделей (не учитывать их), а смотреть исключительно на прогноз переобученной модели, чуть ли не дублируя его по каждому объекту. Для этого нужно, и вправду, разделять выборку для базовых моделей и метамодели. \n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Как выглядит обучение и применение алгоритма случайного леса?*: \n",
    "\n",
    "1.\tСоздаем с помощью бутстрэпа N выборок. Обучаем на каждой дерево со своими отдельными параметрами. Когда приходит новый объект, мы усредняем предсказания отдельных деревьев и выдаем это как ответ.\n",
    "2.\tСоздаем с помощью бутстрэпа N выборок. Обучаем N одинаковых деревьев – каждое на своей выборке, при этом в каждой вершине выбираем случайное подмножество признаков фиксированного размера. Когда приходит новый объект, мы усредняем предсказания отдельных деревьев и выдаем это как ответ.\n",
    "3.\tСоздаем с помощью бутстрэпа N выборок. Обучаем N одинаковых деревьев на каждой, при этом в каждой вершине выбираем случайное подмножество признаков фиксированного размера. Когда приходит новый объект, мы усредняем предсказания отдельных деревьев и выдаем это как ответ.\n",
    "4.\tСоздаем с помощью бутстрэпа N выборок. Обучаем на каждой дерево со своими отдельными параметрами. Когда приходит новый объект, мы складываем предсказания отдельных деревьев и выдаем это как ответ.\n",
    "5.\tСоздаем с помощью бутстрэпа N выборок. Обучаем N одинаковых деревьев на каждой, при этом для каждой выборки выбираем случайное подмножество признаков фиксированного размера. Когда приходит новый объект, мы усредняем предсказания отдельных деревьев и выдаем это как ответ.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ответ: 2)** По построению (определению).\n",
    "\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Блок практики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from scipy.stats import skew\n",
    "\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова потренируемся в предсказании цен на недвижимость из [очередного датасета с каггла](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/)! В качестве основной метрики для валидации моделей будем использовать, как и ранее, `MSLE`.\n",
    "\n",
    "P.S. в данной домашней работе при построении любых моделей, использующих недетерменированные элементы (как бутстрап), в алгоритме указывайте параметр `random_state = 1` для воспроизводимости результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    pd.read_csv('data.csv')\n",
    "    .drop('Id', axis=1)\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Разделим выборку на объекты-таргеты\n",
    "\n",
    "y = df['SalePrice']\n",
    "X = df.drop(columns=['SalePrice'])\n",
    "\n",
    "### Логарифмируем таргет для будущей оптимизации\n",
    "### MSLE через MSE\n",
    "\n",
    "log_target = np.log1p(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Это позволяет получить нормальное распределение таргета\n",
    "### Важно, например, для построения корректной\n",
    "### С точки зрения статистических свойств\n",
    "### Линейной модели.\n",
    "### Хотя здесь мы будем строить ансамбли деревьев, \n",
    "### И это не особо интересно.\n",
    "\n",
    "sns.set(rc={'figure.figsize':(15,10)})\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(y, bins=50)\n",
    "plt.title('Original Data')\n",
    "plt.xlabel('Sale Price')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.distplot(log_target, bins=50)\n",
    "plt.title('Natural Log of Data')\n",
    "plt.xlabel('Natural Log of Sale Price')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В начале поработаем с пропусками!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в какой-либо колонке оказывается достаточно много пропусков, обычно советуют от них избавляться. Мотивировано это тем, что в таких фичах мы можем наблюдать серьезный недостаток информативности, а заполнение пропусков может лишь внести лишнего шума в данные.\n",
    "\n",
    "Избавьтесь от всех колонок, в которых пропусков оказывается больше 15%. (1б)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Можно воспользоваться такой компактной конструкцией\n",
    "\n",
    "X = X.dropna(axis=1, thresh = 0.85*X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вещественные колонки заполните медианным значением по фиче, а категориальные - самой популярной по колонке категорией. (2б)\n",
    "\n",
    "Заметьте, что колонки `MoSold`, `YrSold`, `GarageYrBlt`, `YearBuilt`, `YearRemodAdd` хоть в таблице не являются типами `object`, вряд ли их справедливо использовать как вещественные. Переведите все значения внутри в строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_num_cols = ['MoSold', 'YrSold', 'GarageYrBlt', 'YearBuilt', 'YearRemodAdd']\n",
    "\n",
    "### Выделим категориальные фичи\n",
    "\n",
    "cat_cols = list(X.select_dtypes(include='object').columns)\n",
    "cat_cols += unwanted_num_cols\n",
    "\n",
    "X[cat_cols] = df[cat_cols].astype('object')\n",
    "\n",
    "### Выделим вещественные фичи\n",
    "\n",
    "num_cols = list(X.select_dtypes(exclude='object').columns)\n",
    "num_cols = [ele for ele in num_cols if ele not in unwanted_num_cols]\n",
    "\n",
    "### Заполним пропуски как и хотели!\n",
    "\n",
    "X[num_cols] = X[num_cols].fillna(X[num_cols].median())\n",
    "X[cat_cols] = X[cat_cols].fillna(X[cat_cols].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Отложенная выборка\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    log_target, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите трансформер, который будет делать следующее:\n",
    "\n",
    "1. Масштабирование через StandardScaler для вещественных колонок\n",
    "2. Кодирование через OneHotEncoder для категориальных, содержащих менее, чем 5 уникальных значений\n",
    "3. Кодирование через TargetEncoder для всех остальных категориальных\n",
    "\n",
    "Для этого советуем воспользоваться библиотекой `category_encoders` помимо `sklearn`.\n",
    "\n",
    "А так же классом `ColumnTransformer` из `sklearn.compose`.\n",
    "\n",
    "P.S. Напомним, что для деревьев процедура StandardScaling не обязательна (решающие деревья нечувствительны к масштабу). Тем не менее, это может сделать обучение модели менее тяжелым (хранить большие числа сложно для задач с большим количеством данных)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from category_encoders import TargetEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cols_for_ohe = [x for x in cat_cols if X[x].nunique() < 5]\n",
    "cols_for_mte = [x for x in cat_cols if X[x].nunique() >= 5]\n",
    "\n",
    "cols_for_ohe_idx = [list(X.columns).index(col) for col in cols_for_ohe]\n",
    "cols_for_mte_idx = [list(X.columns).index(col) for col in cols_for_mte]\n",
    "numeric_cols_idx = [list(X.columns).index(col) for col in num_cols]\n",
    "\n",
    "t = [('OneHotEncoder', OneHotEncoder(), cols_for_ohe_idx),\n",
    "     ('MeanTargetEncoder', TargetEncoder(), cols_for_mte_idx),\n",
    "     ('StandardScaler', StandardScaler(), numeric_cols_idx)]\n",
    "\n",
    "col_transform = ColumnTransformer(transformers=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрите, как на наших данных справляется одно Решающее Дерево с дефолтными гиперпараметрами. Добавьте написанный ранее трансформер в модель. (1б)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe_dt = Pipeline([(\"column_transformer\",\n",
    "                     col_transform),\n",
    "                     \n",
    "                    (\"decision_tree\", \n",
    "                     DecisionTreeRegressor())])\n",
    "\n",
    "pipe_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = pipe_dt.predict(X_train)\n",
    "test_preds = pipe_dt.predict(X_test)\n",
    "\n",
    "train_error = np.mean((train_preds - y_train)**2)\n",
    "test_error = np.mean((test_preds - y_test)**2)\n",
    "\n",
    "\n",
    "print(f\"Качество на трейне: {train_error}\")\n",
    "print(f\"Качество на тесте: {test_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Справляется даже без контроля переобучения!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на перформанс Случайного Леса! Подберите параметры по отложенной выборке по данной сетке `param_grid`. Помните, что подбирать количество деревьев не супер обязательно, достаточно поставить их побольше. Что произошло с качеством модели по сравнению с одиноким деревом? (2б)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 1\n",
    "\n",
    "param_grid = {\n",
    "    \"random_forest__max_depth\": [10, 15, 20],\n",
    "    \"random_forest__min_samples_split\": [2, 5, 10],\n",
    "    \"random_forest__min_samples_leaf\": [1, 3, 5]\n",
    "}\n",
    "\n",
    "custom_cv = [(X_train.index.to_list(), X_test.index.to_list())]\n",
    "\n",
    "pipe_rf = Pipeline([(\"column_transformer\",\n",
    "                     col_transform),\n",
    "                     \n",
    "                    (\"random_forest\", \n",
    "                     RandomForestRegressor(random_state=1))])\n",
    "\n",
    "search = GridSearchCV(pipe_rf, \n",
    "                      param_grid, \n",
    "                      cv=custom_cv,\n",
    "                      scoring='neg_mean_squared_error',\n",
    "                      verbose=10)\n",
    "\n",
    "search.fit(X, log_target)\n",
    "\n",
    "print(f\"Best parameter (CV score={search.best_score_:.5f}):\")\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на лучшие параметры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline([(\"column_transformer\",\n",
    "                     col_transform),\n",
    "                     \n",
    "                    (\"random_forest\", \n",
    "                     RandomForestRegressor(max_depth=15,\n",
    "                                           min_samples_leaf=1,\n",
    "                                           min_samples_split=2,\n",
    "                                           random_state=1))])\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = pipe_rf.predict(X_train)\n",
    "test_preds = pipe_rf.predict(X_test)\n",
    "\n",
    "train_error = np.mean((train_preds - y_train)**2)\n",
    "test_error = np.mean((test_preds - y_test)**2)\n",
    "\n",
    "\n",
    "print(f\"Качество на трейне: {train_error}\")\n",
    "print(f\"Качество на тесте: {test_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем теперь поэкспериментировать с бэггингами. \n",
    "\n",
    "Постройте бэггинги с 100 базовыми моделями (и остальными стандартными параметрами) над линейной регрессией, деревом и случайным лесом (бэггинг над бэггингом!). \n",
    "\n",
    "Какое качество у каждой модели на тесте?\n",
    "\n",
    "Какой алгоритм получился лучше с точки зрения качества на тесте? (2б)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "np.random.seed = 1\n",
    "results = []\n",
    "\n",
    "for regressor in [BaggingRegressor(LinearRegression(),\n",
    "                                   n_estimators=100,\n",
    "                                   n_jobs=-1,\n",
    "                                   random_state=1),\n",
    "                  \n",
    "                  BaggingRegressor(RandomForestRegressor(),\n",
    "                                   n_estimators=100, \n",
    "                                   n_jobs=-1,\n",
    "                                   random_state=1), \n",
    "                  \n",
    "                  BaggingRegressor(DecisionTreeRegressor(),\n",
    "                                   n_estimators=100,\n",
    "                                   n_jobs=-1,\n",
    "                                   random_state=1)]:\n",
    "\n",
    "    \n",
    "    pipe_bag = Pipeline([(\"column_transformer\",\n",
    "                          col_transform),\n",
    "                     \n",
    "                         (\"bagging\", \n",
    "                          regressor)])\n",
    " \n",
    "    pipe_bag.fit(X_train, y_train)\n",
    "                 \n",
    "    train_preds = pipe_bag.predict(X_train)\n",
    "    test_preds = pipe_bag.predict(X_test)\n",
    "\n",
    "    train_error = np.mean((train_preds - y_train)**2)\n",
    "    test_error = np.mean((test_preds - y_test)**2)\n",
    "\n",
    "    results.append([train_error, test_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшил ли бэггинг над Лесом качество по сравнению с одним Лесом с точки зрения как качества на тесте, так и на трейне. Как это можно объяснить? Как думаете, много ли смысла в использовании бэггинга над линейными моделями? Выбрали бы вы в данной ситуации именно их в качестве базовых?\n",
    "\n",
    "-- Строить бэггинг над лесом нет смысла, в силу того, что он в отдельности леса оказываются достаточно сильно коррелирующими\n",
    "\n",
    "-- Строить бэггинг над линейными моделями редко когда может дать хоть какой-то прирост в качестве, потому что линейная модель над линейными моделями - это все еще линейная модель. Но даже если строить нелинейную метамодель, то вступает в силу еще один аргумент - линейные модели обладат низким разбросом и слабо друг от друга отличаются, в построении линейной регрессии отсутствует случайность, поэтому, в целом, их выходы будут максимально близки друг к другу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавим новые фичи!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте следующие четыре новые вещественные фичи:\n",
    "\n",
    "1. Отношения площади 1 этажа к общей площади (колонки 1stFlrSF и GrLivArea, в %)\n",
    "2. Отношение Площади завершенного фундамента первого типа к общей площади фундамента (колонки BsmtFinSF1 и TotalBsmtSF, в %)\n",
    "3. Возраст дома (между YearBuilt и YrSold)\n",
    "4. Общая площадь самого дома и фундамента/цоколя (1stFlrSF + 2ndFlrSF + TotalBsmtSF)\n",
    "\n",
    "Обучите заново Случайный лес и найдите лучшие гиперпараметры на старой сетке.\n",
    "\n",
    "Улучшили ли качество модели новые фичи? (4б)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Реализация Функции для подсчета \n",
    "### Отношения площади 1 этажа к общей площади\n",
    "\n",
    "def floor_occupation(x):\n",
    "    \n",
    "    if x[\"GrLivArea\"] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x[\"1stFlrSF\"] * 100 / x[\"GrLivArea\"]\n",
    "\n",
    "\n",
    "X_train[\"1stFlrPercent\"] = X_train.apply(\n",
    "    lambda x: floor_occupation(x), axis=1)\n",
    "\n",
    "X_test[\"1stFlrPercent\"] = X_test.apply(\n",
    "    lambda x: floor_occupation(x), axis=1)\n",
    "\n",
    "X[\"1stFlrPercent\"] = X.apply(\n",
    "    lambda x: floor_occupation(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Реализация Функции для подсчета отношения \n",
    "### Площади завершенного фундамента первого типа к общей площади фундамента\n",
    "\n",
    "\n",
    "def bsmt_finish(x):\n",
    "    \n",
    "    if x[\"TotalBsmtSF\"] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x[\"BsmtFinSF1\"] * 100 / x[\"TotalBsmtSF\"]\n",
    "\n",
    "\n",
    "X_train[\"BsmtFinPercent\"] = X_train.apply(\n",
    "    lambda x: bsmt_finish(x), axis=1)\n",
    "\n",
    "X_test[\"BsmtFinPercent\"] = X_test.apply(\n",
    "    lambda x: bsmt_finish(x), axis=1)\n",
    "\n",
    "X[\"BsmtFinPercent\"] = X.apply(\n",
    "    lambda x: bsmt_finish(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Реализация Функции для возраста\n",
    "\n",
    "\n",
    "def is_house_old(x):\n",
    "    \n",
    "    return int(x['YrSold']) - int(x['YearBuilt'])\n",
    "\n",
    "\n",
    "X_train[\"HowOld\"] = X_train.apply(\n",
    "    lambda x: is_house_old(x), axis=1)\n",
    "\n",
    "X_test[\"HowOld\"] = X_test.apply(\n",
    "    lambda x: is_house_old(x), axis=1)\n",
    "\n",
    "X[\"HowOld\"] = X.apply(\n",
    "    lambda x: is_house_old(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Реализация Функции для общей площади\n",
    "\n",
    "\n",
    "def total_sq(x):\n",
    "\n",
    "     return x[\"1stFlrSF\"] + x[\"2ndFlrSF\"] + x['TotalBsmtSF']\n",
    "\n",
    "\n",
    "X_train[\"TotalSq\"] = X_train.apply(\n",
    "    lambda x: total_sq(x), axis=1)\n",
    "\n",
    "X_test[\"TotalSq\"] = X_test.apply(\n",
    "    lambda x: total_sq(x), axis=1)\n",
    "\n",
    "X[\"TotalSq\"] = X.apply(\n",
    "    lambda x: total_sq(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols_idx = numeric_cols_idx + [X_test.shape[1]-i for i in range(1, 5)]\n",
    "\n",
    "t = [('OneHotEncoder', OneHotEncoder(), cols_for_ohe_idx),\n",
    "     ('MeanTargetEncoder', TargetEncoder(), cols_for_mte_idx),\n",
    "     ('StandardScaler', StandardScaler(), numeric_cols_idx)]\n",
    "\n",
    "col_transform = ColumnTransformer(transformers=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"random_forest__max_depth\": [10, 15, 20],\n",
    "    \"random_forest__min_samples_split\": [2, 5, 10],\n",
    "    \"random_forest__min_samples_leaf\": [1, 3, 5]\n",
    "}\n",
    "\n",
    "pipe_rf = Pipeline([(\"column_transformer\",\n",
    "                     col_transform),\n",
    "                     \n",
    "                    (\"random_forest\", \n",
    "                     RandomForestRegressor(random_state=1))])\n",
    "\n",
    "search = GridSearchCV(pipe_rf, \n",
    "                      param_grid, \n",
    "                      cv=custom_cv,\n",
    "                      scoring='neg_mean_squared_error',\n",
    "                      verbose=10)\n",
    "\n",
    "search.fit(X, log_target)\n",
    "\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline([(\"column_transformer\",\n",
    "                     col_transform),\n",
    "                     \n",
    "                    (\"random_forest\", \n",
    "                     RandomForestRegressor(max_depth=20,\n",
    "                                           min_samples_leaf=1,\n",
    "                                           min_samples_split=2))])\n",
    "\n",
    "pipe_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = pipe_rf.predict(X_train)\n",
    "test_preds = pipe_rf.predict(X_test)\n",
    "\n",
    "train_error = np.mean((train_preds - y_train)**2)\n",
    "test_error = np.mean((test_preds - y_test)**2)\n",
    "\n",
    "\n",
    "print(f\"Качество на трейне: {train_error}\")\n",
    "print(f\"Качество на тесте: {test_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Новые фичи немного помогли!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8db21564b35bbdf2f1295d2e540489014671416f5dc577a5b9d4ca56833a3713"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
